
# Final Project: DEPI Microsoft Machine Learning - Customer Sentiment and Trend Analysis

### Team Members
- **Fares Hazem**
- **Abdallah**
- **Omar**

---

### Project Overview

This project focuses on analyzing customer feedback data to predict sentiment scores (ranging from 1 to 5) using machine learning models. The workflow involves data preprocessing, exploratory data analysis (EDA), machine learning model development, and deployment with Azure services. Additionally, a Generative Adversarial Network (GAN) is implemented to create synthetic feedback data for enhancing the training process.

---

### Repository Structure

```
|-- balanced_df.csv                # Cleaned and balanced dataset ready for analysis
|-- GAN Model.ipynb                # Notebook for developing the GAN model for synthetic data generation
|-- Machine Learning Models with MLflow.py  # Python script integrating MLflow for tracking experiments
|-- Machine Learning Models.ipynb  # Notebook containing traditional ML models (Logistic Regression, SVC, etc.)
|-- mlflow_utils.py                # Utility functions for MLflow integration
|-- NLP Model.ipynb                # Notebook for advanced NLP models, including BERT-based sentiment analysis
|-- Original Data.zip              # Archive containing the raw customer feedback dataset
|-- metrics/                       # Directory containing performance metrics and model evaluation reports
|-- mlruns/                        # Directory containing MLflow experiment runs and logs
|-- __pycache__/                   # Cached Python files (autogenerated)
```

### Project Components

1. **Data Collection and Preprocessing**:
   - Customer feedback data was collected and preprocessed for sentiment analysis.
   - The data was cleaned by removing stop words, applying stemming, and balancing the class distribution.
   - **File**: `balanced_df.csv` contains the cleaned and preprocessed data.

2. **Machine Learning Models**:
   - Several machine learning algorithms were trained and evaluated to predict customer sentiment based on feedback text.
   - The best performing model was an **ensemble** of:
     - **SVC (Support Vector Classifier)**
     - **Logistic Regression**
     - **XGBClassifier (XGBoost)**
   - **Results**: 
     - Training accuracy: **81%**
     - Test accuracy: **56%** (indicating potential overfitting)
   - **Files**:
     - `Machine Learning Models.ipynb`: Contains the code for building and evaluating traditional ML models.
     - `Machine Learning Models with MLflow.py`: Script to track and manage ML experiments using MLflow.

3. **NLP and Deep Learning**:
   - Advanced Natural Language Processing (NLP) models, such as **BERT**, were implemented to improve sentiment classification.
   - **File**: `NLP Model.ipynb` contains the code for fine-tuning and evaluating NLP models.

4. **Generative Adversarial Network (GAN)**:
   - A GAN was built to generate synthetic customer feedback data, improving the training process with more diverse input.
   - **File**: `GAN Model.ipynb` contains the implementation of the GAN model.

5. **MLOps and Model Tracking**:
   - **MLflow** was used to track experiments, monitor model performance, and manage the deployment pipeline.
   - **Files**:
     - `Machine Learning Models with MLflow.py`: Integration of MLflow for experiment tracking.
     - `mlflow_utils.py`: Utility functions for working with MLflow.
     - `mlruns/`: Stores the results and logs from all tracked experiments.

6. **Deployment**:
   - The final model was deployed using **Azure Machine Learning** to enable real-time sentiment prediction.
   - Integration with Azure ensured scalability and easy access for end-users.

---

### Results and Next Steps

- While the model achieved **81% accuracy** on the training set, its **56% accuracy** on the test set indicated overfitting. After this, a **pretrained BERT model** was also applied, but the results were still **56%** on the test set, leading us to realize that the issue likely lies in the data itself. Due to time constraints, we continued with the same accuracy for the final deliverables.
- Future steps include:
  - Investigating and improving the data quality or collecting more diverse data.
  - Further exploring deep learning models to improve generalization, including experimenting with **neural networks** for better performance.

---


Special thanks to our instructor and supervisor, **Eng. Seif Koretum**, for his invaluable guidance and support throughout this project.
